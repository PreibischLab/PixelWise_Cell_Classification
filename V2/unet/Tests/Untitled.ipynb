{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MeanIoU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9109496d74d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-9109496d74d3>\u001b[0m in \u001b[0;36munet_valid\u001b[0;34m(pretrained_weights, input_size, output_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMeanIoU\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#  loss : mse / categorical_crossentropy sparse_categorical_crossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeanIoU' is not defined"
     ]
    }
   ],
   "source": [
    "def unet_valid(pretrained_weights = None,input_size = (572,572,4),output_size = 3):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv1)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) # 284\n",
    "\n",
    "    conv1 = tf.keras.layers.Cropping2D(cropping=((88,88), (88,88)))(conv1) # 568 -> 392\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv2)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) # 140\n",
    "\n",
    "    conv2 = tf.keras.layers.Cropping2D(cropping=((40,40), (40,40)))(conv2) # 280 -> 200\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv3)\n",
    "   \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3) # 68\n",
    "  \n",
    "    conv3 = tf.keras.layers.Cropping2D(cropping=((16,16), (16,16)))(conv3) # 136 -> 104\n",
    "   \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv4)\n",
    "    \n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4) # 32\n",
    "   \n",
    "    conv4 = tf.keras.layers.Cropping2D(cropping=((4,4), (4,4)))(drop4) # 64 -> 56\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv5)\n",
    "\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "  \n",
    "    merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(output_size, (1,1), activation = 'softmax')(conv9)\n",
    "\n",
    "#     model = Model(input = inputs, output = conv10)\n",
    "\n",
    "#     changed to work in TF2.0\n",
    "    model = Model(inputs, conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics=['accuracy',MeanIoU( num_classes=output_size)])\n",
    "    \n",
    "#  loss : mse / categorical_crossentropy sparse_categorical_crossentropy\n",
    "#  metrics: MeanIoU(num_classes=4)\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = unet_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(None, 64, 64, 512), (None, 55, 55, 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 24, 24, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 1\n",
    "NUM_BOXES = 5\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "CHANNELS = 3\n",
    "CROP_SIZE = (24, 24)\n",
    "\n",
    "image = tf.random.normal(shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH,\n",
    "CHANNELS) )\n",
    "print(image.shape)\n",
    "boxes = tf.random.uniform(shape=(NUM_BOXES, 4))\n",
    "box_indices = tf.random.uniform(shape=(NUM_BOXES,), minval=0,\n",
    "maxval=BATCH_SIZE, dtype=tf.int32)\n",
    "output = tf.image.crop_and_resize(image, boxes, box_indices, CROP_SIZE)\n",
    "output.shape  #=> (5, 24, 24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[[1.0, 2.0, 3.0],\n",
    "      [4.0, 5.0, 6.0],\n",
    "      [7.0, 8.0, 9.0],\n",
    "      [10.0, 11.0, 12.0]],\n",
    "    [[13.0, 14.0, 15.0],\n",
    "      [16.0, 17.0, 18.0],\n",
    "      [19.0, 20.0, 21.0],\n",
    "      [22.0, 23.0, 24.0]],\n",
    "    [[25.0, 26.0, 27.0],\n",
    "      [28.0, 29.0, 30.0],\n",
    "      [31.0, 32.0, 33.0],\n",
    "      [34.0, 35.0, 36.0]],\n",
    "    [[37.0, 38.0, 39.0],\n",
    "      [40.0, 41.0, 42.0],\n",
    "      [43.0, 44.0, 45.0],\n",
    "      [46.0, 47.0, 48.0]]]\n",
    "y = tf.image.central_crop(x, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 24, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_shape = (2, 28, 28, 3)\n",
    "x = np.arange(np.prod(input_shape)).reshape(input_shape)\n",
    "y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
