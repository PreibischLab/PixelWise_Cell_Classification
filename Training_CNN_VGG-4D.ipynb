{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 124\n",
    "InputPath = \"data/pickle/\"\n",
    "X = pickle.load(open(InputPath+\"X2_4d_masked.pickle\",\"rb\"))\n",
    "y = pickle.load(open(InputPath+\"y2_4d_masked.pickle\",\"rb\"))\n",
    "X,y=shuffle(X,y, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0, 0, 0, 0, 0]\n",
    "for i in y:\n",
    "    weights[i[0]]= weights[i[0]]+1\n",
    "weights = np.array(weights)\n",
    "weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = weights / sum(weights)\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0, 300, 300, 300, 0]\n",
    "newX = []\n",
    "newY = []\n",
    "for i, (a, b) in enumerate(zip(X, y)):\n",
    "    if(weights[b[0]]>0):\n",
    "        weights[b[0]]= weights[b[0]]-1\n",
    "        newX.append(a)\n",
    "        newY.append(b[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0, 0, 0, 0, 0]\n",
    "for i in newY:\n",
    "    weights[i]= weights[i]+1\n",
    "weights = np.array(weights)\n",
    "weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X/255.0\n",
    "y = tf.keras.utils.to_categorical(newY).astype(int)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.amax(X))\n",
    "\n",
    "print(np.amin(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newX\n",
    "X = np.array(X).reshape(-1,80,80,4)\n",
    "y = np.array(y).reshape(-1,3)\n",
    "X,y=shuffle(X,y, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,50))\n",
    "# for i in range(15):\n",
    "#     plt.subplot(5,3,i+1)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "#     plt.grid(False)\n",
    "#     plt.imshow(train_X[i], cmap=plt.cm.binary)\n",
    "#     plt.xlabel(str(train_y[i]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME = \"Cnn64x2-{}-fix_X_withActivation\".format(int(time.time()))\n",
    "# from models import simple_cnn_model\n",
    "# model = simple_cnn_model()\n",
    "# model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer=tf.keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = [301, 493, 531, 329, 628]\n",
    "# weights = [286, 459, 512, 317, 600]\n",
    "# total = sum(weights)\n",
    "# weights[:] = [x / total for x in weights]\n",
    "# print(weights)\n",
    "classWeights = { i : weights[i] for i in range(0, len(weights) ) }\n",
    "classWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"VGG-updated_{}\".format(int(time.time()))\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VGG_16\n",
    "model = VGG_16()\n",
    "adam = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#         samplewise_center=False,  # set each sample mean to 0\n",
    "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#         samplewise_std_normalization=False,  # divide each input by its std\n",
    "#         zca_whitening=False,  # apply ZCA whitening\n",
    "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#         horizontal_flip=True,  # randomly flip images\n",
    "#         vertical_flip=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "                            rotation_range=360,\n",
    "                             width_shift_range=0.05,\n",
    "                             height_shift_range=0.05,\n",
    "                             shear_range=0.10,\n",
    "                             zoom_range=0.3,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True,\n",
    "                             brightness_range=[0.8,1.0],\n",
    "                             rescale=1./255.\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = datagen.flow(train_X, train_y, batch_size=1)\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.tight_layout()\n",
    "# for i in range(36):\n",
    "#     plt.subplot(6,6,i+1)\n",
    "#     plt.axis('off')\n",
    "#     batch = it.next()\n",
    "#     image = batch[0]\n",
    "#     label = batch[1][0]\n",
    "#     print(np.min(image), np.max(image), np.mean(image), np.std(image))\n",
    "#     plt.imshow(image[0,:,:,0])\n",
    "#     plt.text(10,30,label, color='green', size=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# checkpoint_path = \"models/\"+NAME+\"-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint_path = \"models/\"+NAME+\".hdf5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=0, \n",
    "#                                 save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=0, save_best_only=False, mode='max')\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1,\n",
    "#     save_best_only=True, save_weights_only=False,save_frequency=100)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/scalars/\" + NAME\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# oldStdout = sys.stdout\n",
    "# file = open('trainLog.txt', 'w')\n",
    "# sys.stdout = file\n",
    "# class_weight=classWeights,callbacks=[cp_callback,tensorboard_callback]\n",
    "# history = model.fit_generator(datagen.flow(train_X, train_y, batch_size=32), epochs=100, \n",
    "#                     validation_data=(test_X, test_y))\n",
    "\n",
    "history = model.fit(x=train_X, y=train_y, batch_size=64, epochs=100, \n",
    "                    validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import Plot\n",
    "test_loss, test_acc = model.evaluate(test_X,  test_y, verbose=2)\n",
    "\n",
    "Plot.plot_accuracy_curve(history)\n",
    "y_pred = model.predict(test_X)\n",
    "map_characters = {0:'Dead',1:'1',2:'2',3:'3',4:'Complex'}\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(test_y > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n",
    "Y_pred_classes = np.argmax(y_pred,axis=1) \n",
    "Y_true = np.argmax(test_y,axis=1)\n",
    "# plotKerasLearningCurve()\n",
    "# plt.show()  \n",
    "Plot.plot_learning_curve(history)\n",
    "plt.show()\n",
    "map_characters = {0:'Dead',1:'1',2:'2',3:'3',4:'Complex'}\n",
    "confusion_mtx = sklearn.metrics.confusion_matrix(Y_true, Y_pred_classes) \n",
    "Plot.plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values())) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "\n",
    "# NAME = \"VGG_withoutRegulation-{}\".format(int(time.time()))\n",
    "\n",
    "\n",
    "# # checkpoint_path = \"models/\"+NAME+\"-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "# checkpoint_path = \"models/\"+NAME+\".hdf5\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# # cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=0, \n",
    "# #                                 save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# # checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=0, save_best_only=False, mode='max')\n",
    "# # cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1,\n",
    "# #     save_best_only=True, save_weights_only=False,save_frequency=100)\n",
    "\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# # datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# logdir = \"logs/scalars/\" + NAME\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# history = model.fit(x=train_X, y=train_y, batch_size=64, epochs=1000, \n",
    "#                     validation_data=(test_X, test_y),class_weight=classWeights,callbacks=[cp_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
